# -*- coding: utf-8 -*-
"""2015312904_KwonJoonWoo_TF

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NjYSsvkK1XGYOQaWLBI6yWaJ6PqFIxOr
"""

import nltk
import json
from nltk.tokenize import word_tokenize
from google.colab import files

# Settings
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')

path = '/content/drive/My Drive/test/bbc_articles.json'
with open(path,'r') as f:
  json_data = json.load(f)

keylist = json_data.keys()
print(keylist)

newpath = '/content/drive/My Drive/test/2015312904_KwonJoonWoo_TF.txt'
f = open(newpath,'w')

# Settings
list=[]
TF_list = []
temp_list = []
sample_list=['VB','VBD','VBG','VBN','VBP','VBZ','NN','NNS','NNP','NNPS']

# Extract Morpheme and sort alphabetically 
for i in keylist:
  num=1
  for temp in json_data[i]:
    tokens = word_tokenize(temp)
    tagged_tokens = nltk.pos_tag(tokens)
    new_num = str(num)
    f.write('('+i+new_num+')'+'\n')
    num += 1

    for (word,pos) in tagged_tokens:
      new_word = word.lower()
      renew_word = new_word+'/'+pos
      if renew_word not in list:
        if pos in sample_list:
          list.append(renew_word)
    list.sort()

    # Data revision
    for (word,pos) in tagged_tokens:
      new_word = word.lower()
      renew_word = new_word+'/'+pos
      temp_list.append(renew_word)

    # Calculating Term Frequency
    for k in list:
      TF = 0
      TF=temp_list.count(k)
      TF_list.append(TF)

    # Display Term Frequency
    morpheme = list
    value = TF_list
    select = [morpheme,value]
    dic = dict(zip(*select))
    for morpheme, value in dic.items():
      f.write('{}\tTF: {}'.format(morpheme, value))
      f.write('\n')

    # Initialization
    del list[:]
    del temp_list[:]
    del TF_list[:]
    f.write('\n')
    f.write('\n')


from google.colab import drive
drive.mount('/content/drive')

